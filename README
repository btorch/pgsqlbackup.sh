
- INSTALLATION 

    1. The following GNU utilities needs to be available prior to usage of this script 

        - sed   he GNU sed stream editor
        - mutt  text-based mailreader supporting MIME, GPG,PGP and threading    (If you want attached files)
        - awk   a pattern scanning and text processing language
        - mail  GNU mailutils utilities for handling mail 
        - gzip  GNU compression utilities                       (If you want to use gzip compression instead of bzip2)
        - bzip2 high-quality block-sorting file compressor      (default - must be available)


    2. After verifing all those packages are available 
        
        - Copy pgsqlbackup.sh to a location that is accessible by the postgres superuser (e.g: /usr/local/bin)
        - Change file mode to 750 
        - Create a cronjob under the postgres superuser account to backup the database(s)
        _ If you would like to push the backups to the Cloud please check "Cloud Configuration & Setup" 
          after reading the "configuration" section below




- CONFIGURATION

    1. Main Configuration Parameters 

        - USERNAME      . Should be the "postgres" superuser or any other superuser (postgres recommended)
        - CONN_TYPE     . A TCP/IP or Socket connection path must be setup. The superuser above must be allowed to auth through it (pg_hba.conf)
        - DBNAMES       . The Default is set to "all", but you can provide a space separated list
        - BACKUPDIR     . Location where the backups will be stored (superuser MUST have read+write access)
        - PATH          . Add any additional paths if desired
        - HOST          . Full HOSTNAME is picked up automatically but can be set manually if desired


    2. Mail Configuration Parameters

        - MAILCONTENT   . Could be set to files, stdout, maillogs and quiet (More info on "MAIL SETUP" section of script)
        - MAXATTSIZE    . Max email size (default is 4MB)
        - MAILADDR      . Email address


    3. Advanced Configuration Parameters

        - VACUUM            . Default is set to 0 (0 = NoVacuum, 1 = VacuumOnly, 2 = Vacuum & Analyze, 3 = FullVacuum)
        - CREATE_DATABASE   . Yes or No for including CREATE DATABASE command on the backups (Default is yes)
        - DUMP_OIDS         . Include or not OIDs on backup dump (default is no)
        - COMP              . Compression type gzip or bzip2 (default is bzip2)
        - DUMP_OPT          . Dump format can be; custom = Fc , Custom tar = Ft , SQL plain text = Fp (Default is Fc)
        - RETENTION         . Keep a one day retention on the drive (Default is yes)
        - EXTRA_OPTS        . Any other options you might wanna pass to the postgresql dump utility 




 
- CLOUD CONFIGURATION & SETUP ( in the works )

    1. Install "cloudfiles.sh" or "st.py" utility 

        * For "cloudfiles.sh" 
            - Download from git://github.com/btorch/cloudfiles.sh.git
            - Install it under desired location
            - Change mode to 755 
        * For "st.py"
            - Download from https://github.com/openstack/swift/raw/master/bin/st
            - Install it under desired location
            - Change mode to 755


    2. CloudFiles Configuration Parameters ( script has no support for files over 5GB yet )

        - CF_BACKUP     . Enable pushing the backups to CloudFiles  (default is disabled)
        - CF_UTIL       . Location of the cloudfiles.sh or st.py utility    
        - CF_PUSH       . Push all files or just the dumps with no logs ("all" or "nologs")
        - CF_CONTAINER  . Cloud container to push files into 
        - CF_USER       . CF Username
        - CF_KEY        . CF api key or DevAuth/SwAuth password
        - CF_REG        . CF Region (Could be US or UK) (required for "cloudfiles.sh utility)
        - CF_AUTH       . CF AUTH URL (required for "st" utility) 
        - CF_ACCOUNT    . CF ACCOUNT a user belongs to (required for "st" utility when using DevAuth/SwAuth auth systems)


    3. S3 Configuration Parameters (FUTURE WORK)

        - S3_BACKUP     . Enable pushing the backups to CloudFiles  (default is disabled)
        - S3_UTIL       . Location of the cloudfiles.sh utility    
        - S3_PUSH       . Push all files or just the dumps with no logs ("all" or "nologs")
        - S3_CONTAINER  . Cloud container to push files into 
        - S3_USER       . CF Username
        - S3_KEY        . CF api key
        - S3_REG        . CF Region (Could be us or uk)


